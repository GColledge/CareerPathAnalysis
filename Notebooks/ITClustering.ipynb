{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyFunctions import prettify\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans #this is currently an arbitrary choice.\n",
    "#More thought should be put into what model to use.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the corpus\n",
    "Here I am building the feature array that will be used to classify career paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfSamples = 1000;\n",
    "numberOfFeatures = 10\n",
    "initialList = ['software_engineer','information_technology_specialist','data','software_developer','computer_scientist',\n",
    "               'sales_manager','human_resource','business','executive','design']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['software engineer', 'information technology specialist', 'data', 'software developer', 'computer scientist', 'sales manager', 'human resource', 'business', 'executive', 'design']\n",
      "\n",
      "Features:\n",
      "0:\tbusiness\n",
      "1:\tcomputer\n",
      "2:\tdata\n",
      "3:\tdesign\n",
      "4:\tdeveloper\n",
      "5:\tengineer\n",
      "6:\texecutive\n",
      "7:\thuman\n",
      "8:\tinformation\n",
      "9:\tsoftware\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for path in initialList:\n",
    "    titlesList = prettify(path)\n",
    "    for title in titlesList:\n",
    "       corpus.append(title) \n",
    "print(corpus[0:30])\n",
    "#The vectorizer makes an array of features (words) that are used in the corpus.\n",
    "#The Job paths are then characterized using this array and classified.\n",
    "vectorizer = CountVectorizer(min_df=0.01, max_df=0.75, max_features=numberOfFeatures)\n",
    "vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"\\nFeatures:\")\n",
    "for i in range(0,len(vectorizer.vocabulary_)):\n",
    "    print(str(i) + \":\\t\" + vectorizer.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the file and process\n",
    "here we read in the file line by line into a list of career paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each career path becomes it own list. \n",
    "pathList = [] # The list of career paths\n",
    "DataFile = open(\"/Users/gregorycolledge/gcolledge/gcolledge/MSD_6019/allPaths.txt\");\n",
    "for i in range(0,numberOfSamples):\n",
    "    careerPath = DataFile.readline();\n",
    "    careerPathList = prettify(careerPath);\n",
    "    pathString = \"\"\n",
    "    for title in careerPathList:\n",
    "        pathString = pathString + \" \" + title\n",
    "    pathList.append([pathString]);\n",
    "DataFile.close();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am turning the career path strings into feature vectors (vectorized rows) in preperation of using the clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedRows = []\n",
    "for path in pathList:\n",
    "    temp = vectorizer.transform(path)\n",
    "    vectorizedRows.append(temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am making the model. The vectorized rows list has to be turned to an array and reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 10)\n",
      "(1000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=4, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(vectorizedRows).shape)#shows number of rows used for clustering, number of samples per line, number of features per sample.\n",
    "print(np.array(vectorizedRows).reshape(numberOfSamples,numberOfFeatures).shape) #number of samples, number of features\n",
    "kmeans = KMeans(n_clusters=3, random_state=4)\n",
    "kmeans.fit(np.array(vectorizedRows).reshape(numberOfSamples,numberOfFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, -0.0, 0.0, 4.0]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, -0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "clusterPoints = [];\n",
    "for line in kmeans.cluster_centers_:\n",
    "    newLine = [];\n",
    "    for num in line:\n",
    "        newLine.append(round(num));\n",
    "    clusterPoints.append(newLine);\n",
    "for each in clusterPoints:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 0 2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "test = vectorizer.transform(['bum','software engineer','program manager',' administrative professional maternity and family leave customer service associate patient services coordinator clinical admin team lead credentialing specialist managed care credentialing specialist credentialing verification office',' software developer intern teaching assistant software engineer software engineer software engineer','senior technical recruiter', 'software engineer software engineer software engineer software engineer software engineer software engineer software engineer software engineer software engineer software engineer software engineer software engineer software engineer software engineer', 'computer programmer', 'technical program manager', 'machine leraning specialist and data analyst'])\n",
    "result = kmeans.predict(np.array(test.toarray()))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
